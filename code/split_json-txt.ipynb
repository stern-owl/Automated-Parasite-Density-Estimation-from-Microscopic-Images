{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65d0fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0489492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CHANGE THESE PATHS ===\n",
    "image_dir = \"D:/SOP_BIO/dataset/images/train\"\n",
    "label_dir = \"D:/SOP_BIO/wbc/txt\"\n",
    "output_dir = \"D:/SOP_BIO/WBC_dataset\"\n",
    "split_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1ee828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Copied 41 training and 11 validation pairs.\n"
     ]
    }
   ],
   "source": [
    "# === Create output folders ===\n",
    "for split in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(output_dir, 'images', split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels', split), exist_ok=True)\n",
    "\n",
    "# === Collect valid image-label pairs ===\n",
    "image_label_pairs = []\n",
    "for label_file in os.listdir(label_dir):\n",
    "    if not label_file.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    image_name = label_file.replace('.txt', '.jpg')  # assume .jpg; change if using .png\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "    if os.path.exists(image_path):\n",
    "        image_label_pairs.append((image_path, label_path))\n",
    "\n",
    "# === Split the data ===\n",
    "train_pairs, val_pairs = train_test_split(image_label_pairs, train_size=split_ratio, random_state=42)\n",
    "\n",
    "# === Copy files ===\n",
    "def copy_files(pairs, split):\n",
    "    for img_path, label_path in pairs:\n",
    "        shutil.copy(img_path, os.path.join(output_dir, 'images', split, os.path.basename(img_path)))\n",
    "        shutil.copy(label_path, os.path.join(output_dir, 'labels', split, os.path.basename(label_path)))\n",
    "\n",
    "copy_files(train_pairs, 'train')\n",
    "copy_files(val_pairs, 'val')\n",
    "\n",
    "print(f\"✅ Copied {len(train_pairs)} training and {len(val_pairs)} validation pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad38baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# === CHANGE THESE ===\n",
    "image_dir = \"D:/SOP_BIO/dataset/images/train\"\n",
    "json_dir = \"D:/SOP_BIO/wbc\"\n",
    "output_txt_dir = \"D:/SOP_BIO/wbc/txt\"\n",
    "os.makedirs(output_txt_dir, exist_ok=True)\n",
    "\n",
    "# \n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4af8e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted: 20190404151312.jpg → D:/SOP_BIO/wbc/txt\\20190404151312.txt\n",
      "✅ Converted: 20190404151511.jpg → D:/SOP_BIO/wbc/txt\\20190404151511.txt\n",
      "✅ Converted: 20190404151641.jpg → D:/SOP_BIO/wbc/txt\\20190404151641.txt\n",
      "✅ Converted: 20190404152216.jpg → D:/SOP_BIO/wbc/txt\\20190404152216.txt\n",
      "✅ Converted: 20190404152626.jpg → D:/SOP_BIO/wbc/txt\\20190404152626.txt\n",
      "✅ Converted: 20190404152850.jpg → D:/SOP_BIO/wbc/txt\\20190404152850.txt\n",
      "✅ Converted: 20190404153102.jpg → D:/SOP_BIO/wbc/txt\\20190404153102.txt\n",
      "✅ Converted: 20190404153544.jpg → D:/SOP_BIO/wbc/txt\\20190404153544.txt\n",
      "✅ Converted: 20190404154509.jpg → D:/SOP_BIO/wbc/txt\\20190404154509.txt\n",
      "✅ Converted: 20190404154805.jpg → D:/SOP_BIO/wbc/txt\\20190404154805.txt\n",
      "✅ Converted: 20190404155033.jpg → D:/SOP_BIO/wbc/txt\\20190404155033.txt\n",
      "✅ Converted: 20190404155314.jpg → D:/SOP_BIO/wbc/txt\\20190404155314.txt\n",
      "✅ Converted: 20190404155447.jpg → D:/SOP_BIO/wbc/txt\\20190404155447.txt\n",
      "✅ Converted: 20190404160306.jpg → D:/SOP_BIO/wbc/txt\\20190404160306.txt\n",
      "✅ Converted: 20190404160758.jpg → D:/SOP_BIO/wbc/txt\\20190404160758.txt\n",
      "✅ Converted: 20190404161024.jpg → D:/SOP_BIO/wbc/txt\\20190404161024.txt\n",
      "✅ Converted: 20190405152552.jpg → D:/SOP_BIO/wbc/txt\\20190405152552.txt\n",
      "✅ Converted: 20190405153126.jpg → D:/SOP_BIO/wbc/txt\\20190405153126.txt\n",
      "✅ Converted: 20190405154209.jpg → D:/SOP_BIO/wbc/txt\\20190405154209.txt\n",
      "✅ Converted: 20190405154730.jpg → D:/SOP_BIO/wbc/txt\\20190405154730.txt\n",
      "✅ Converted: 20190405162132.jpg → D:/SOP_BIO/wbc/txt\\20190405162132.txt\n",
      "✅ Converted: 20190410173051.jpg → D:/SOP_BIO/wbc/txt\\20190410173051.txt\n",
      "✅ Converted: 20190410173623.jpg → D:/SOP_BIO/wbc/txt\\20190410173623.txt\n",
      "✅ Converted: 20190410174108.jpg → D:/SOP_BIO/wbc/txt\\20190410174108.txt\n",
      "✅ Converted: 20190410174403.jpg → D:/SOP_BIO/wbc/txt\\20190410174403.txt\n",
      "✅ Converted: 20190410182435.jpg → D:/SOP_BIO/wbc/txt\\20190410182435.txt\n",
      "✅ Converted: 20190410182610.jpg → D:/SOP_BIO/wbc/txt\\20190410182610.txt\n",
      "✅ Converted: 20190410182928.jpg → D:/SOP_BIO/wbc/txt\\20190410182928.txt\n",
      "✅ Converted: 20190414103417.jpg → D:/SOP_BIO/wbc/txt\\20190414103417.txt\n",
      "✅ Converted: 20190414103616.jpg → D:/SOP_BIO/wbc/txt\\20190414103616.txt\n",
      "✅ Converted: 20190414103754.jpg → D:/SOP_BIO/wbc/txt\\20190414103754.txt\n",
      "✅ Converted: 20190414104255.jpg → D:/SOP_BIO/wbc/txt\\20190414104255.txt\n",
      "✅ Converted: 20190414104848.jpg → D:/SOP_BIO/wbc/txt\\20190414104848.txt\n",
      "✅ Converted: 20190414111121.jpg → D:/SOP_BIO/wbc/txt\\20190414111121.txt\n",
      "✅ Converted: 20190414114218.jpg → D:/SOP_BIO/wbc/txt\\20190414114218.txt\n",
      "✅ Converted: 20190414121149.jpg → D:/SOP_BIO/wbc/txt\\20190414121149.txt\n",
      "✅ Converted: 20190414121909.jpg → D:/SOP_BIO/wbc/txt\\20190414121909.txt\n",
      "✅ Converted: 20190414122004.jpg → D:/SOP_BIO/wbc/txt\\20190414122004.txt\n",
      "✅ Converted: 20190415175339.jpg → D:/SOP_BIO/wbc/txt\\20190415175339.txt\n",
      "✅ Converted: 20190415175738.jpg → D:/SOP_BIO/wbc/txt\\20190415175738.txt\n",
      "✅ Converted: 20190415181133.jpg → D:/SOP_BIO/wbc/txt\\20190415181133.txt\n",
      "✅ Converted: 20190415222128.jpg → D:/SOP_BIO/wbc/txt\\20190415222128.txt\n",
      "✅ Converted: 20190415222604.jpg → D:/SOP_BIO/wbc/txt\\20190415222604.txt\n",
      "✅ Converted: 20190415224003.jpg → D:/SOP_BIO/wbc/txt\\20190415224003.txt\n",
      "✅ Converted: 20190415224213.jpg → D:/SOP_BIO/wbc/txt\\20190415224213.txt\n",
      "✅ Converted: 20190415224407.jpg → D:/SOP_BIO/wbc/txt\\20190415224407.txt\n",
      "✅ Converted: 20190415224914.jpg → D:/SOP_BIO/wbc/txt\\20190415224914.txt\n",
      "✅ Converted: 20190417160703.jpg → D:/SOP_BIO/wbc/txt\\20190417160703.txt\n",
      "✅ Converted: 20190417161600.jpg → D:/SOP_BIO/wbc/txt\\20190417161600.txt\n",
      "✅ Converted: 20190417163939.jpg → D:/SOP_BIO/wbc/txt\\20190417163939.txt\n",
      "✅ Converted: 20190417174239.jpg → D:/SOP_BIO/wbc/txt\\20190417174239.txt\n",
      "✅ Converted: 20190418140110.jpg → D:/SOP_BIO/wbc/txt\\20190418140110.txt\n"
     ]
    }
   ],
   "source": [
    "#  === Iterate through JSON files ===\n",
    "for json_file in os.listdir(json_dir):\n",
    "    if not json_file.endswith(\".json\"):\n",
    "        continue\n",
    "\n",
    "    json_path = os.path.join(json_dir, json_file)\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Each JSON contains a list of entries (one per image)\n",
    "    for entry in data:\n",
    "        image_name = entry['image']\n",
    "        annotations = entry['annotations']\n",
    "        img_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"⚠️ Image not found: {image_name}\")\n",
    "            continue\n",
    "\n",
    "        # Get image size\n",
    "        with Image.open(img_path) as img:\n",
    "            img_w, img_h = img.size\n",
    "\n",
    "        # Output YOLO file\n",
    "        txt_path = os.path.join(output_txt_dir, os.path.splitext(image_name)[0] + \".txt\")\n",
    "\n",
    "        with open(txt_path, 'w') as out:\n",
    "            for ann in annotations:\n",
    "                cls_id = 0  # 'wbc' → class 0\n",
    "                x_center = ann['coordinates']['x'] / img_w\n",
    "                y_center = ann['coordinates']['y'] / img_h\n",
    "                width = ann['coordinates']['width'] / img_w\n",
    "                height = ann['coordinates']['height'] / img_h\n",
    "\n",
    "                out.write(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "        print(f\"✅ Converted: {image_name} → {txt_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biosop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
